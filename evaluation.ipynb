{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from util.image import unnormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from net import PConvUNet\n",
    "from celeb import CelebA\n",
    "import opt\n",
    "from util.io import load_ckpt\n",
    "\n",
    "class Argument():\n",
    "    def __init__(self):\n",
    "        self.root = './data_original'\n",
    "        self.mask_root = './irregular_mask/disocclusion_img_mask/'\n",
    "        self.save_dir = './snapshots/default'\n",
    "        self.log_dir = './logs/default'\n",
    "        self.lr = 0.0008\n",
    "        self.lr_finetune = 0.0001\n",
    "        self.max_iter = 9999999\n",
    "        self.batch_size = 24\n",
    "        self.n_threads = 4\n",
    "        self.save_model_interval = 1000\n",
    "        self.vis_interval = 500\n",
    "        self.log_interval = 100\n",
    "        self.image_size = 512\n",
    "args = Argument()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "size = (args.image_size, args.image_size)\n",
    "img_tf = transforms.Compose(\n",
    "    [transforms.Resize(size=size), transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=opt.MEAN, std=opt.STD)])\n",
    "mask_tf = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(size=size),\n",
    "#         transforms.Resize(size=size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "dataset_val = CelebA(args.root, args.mask_root, img_tf, mask_tf, 'test_')\n",
    "\n",
    "lr = args.lr\n",
    "model = PConvUNet()\n",
    "model = PConvUNet().to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "ckpt_name = './snapshots/default/ckpt/86000.pth'\n",
    "start_iter = load_ckpt(\n",
    "    ckpt_name, [('model', model)], [('optimizer', optimizer)])\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = lr\n",
    "print('Starting from iter ', start_iter)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def evaluate(model, dataset, device, filename, image_num=8):\n",
    "    image, mask, gt = zip(*[dataset[i] for i in range(image_num)])\n",
    "    image = torch.stack(image)\n",
    "    mask = torch.stack(mask)\n",
    "    gt = torch.stack(gt)\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image.to(device), mask.to(device))\n",
    "    output = output.to(torch.device('cpu'))\n",
    "    output_comp = mask * image + (1 - mask) * output\n",
    "\n",
    "    grid = make_grid(\n",
    "        torch.cat((unnormalize(image), mask, unnormalize(output),\n",
    "                   unnormalize(output_comp), unnormalize(gt)), dim=0),\n",
    "        nrow=image_num\n",
    "    )\n",
    "#     save_image(grid, filename)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "i = start_iter\n",
    "image_num = 5\n",
    "grid = evaluate(model, dataset_val, device,\n",
    "                '{:s}/images/org_test_{:d}.jpg'.format(args.save_dir, i + 1),\n",
    "               image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_val\n",
    "image_num=6\n",
    "# image, mask, gt = zip(*[dataset[i] for i in range(image_num)])\n",
    "image, mask, gt = zip(*[dataset[0] for i in range(image_num)])\n",
    "image = torch.stack(image)\n",
    "mask = torch.stack(mask)\n",
    "gt = torch.stack(gt)\n",
    "with torch.no_grad():\n",
    "    output, _ = model(image.to(device), mask.to(device))\n",
    "output = output.to(torch.device('cpu'))\n",
    "output_comp = mask * image + (1 - mask) * output\n",
    "\n",
    "grid = make_grid(\n",
    "    torch.cat((unnormalize(image), mask, unnormalize(output),\n",
    "               unnormalize(output_comp), unnormalize(gt)), dim=0),\n",
    "    nrow=image_num\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(grid.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data_original/output/029.jpg'\n",
    "save_image(grid, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
