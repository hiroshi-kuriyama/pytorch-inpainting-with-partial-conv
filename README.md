# pytorch-inpainting-with-partial-conv

## 自分用追記
-------------------
CelebA-HQ(512x512)のデータを学習するように修正した。(https://drive.google.com/drive/folders/11Vz0fqHS2rXDb5pprgTjpD7S2BAJhi1P)
mask画像もNVIDIAのサイトからダウンロードした。(https://nv-adlr.github.io/publication/partialconv-inpainting)

trainの実行はtrain.ipynbから

参考ブログ：
https://qiita.com/saneatsu/items/da06e8632c7f5ba65279
https://woodyzootopia.github.io/2018/12/%E8%AB%96%E6%96%87%E8%A7%A3%E8%AA%ACpartial-convolution/
https://www.mahirokazuko.com/entry/2018/09/13/154420
-------------------



**[Official implementation](https://github.com/NVIDIA/partialconv) is released by the authors.**

**Note that this is an ongoing re-implementation and I cannot fully reproduce the results. Suggestions and PRs are welcome!**

This is an unofficial pytorch implementation of a paper, [Image Inpainting for Irregular Holes Using Partial Convolutions](https://arxiv.org/abs/1804.07723) [Liu+, arXiv2018].

## Requirements
- Python 3.6+
- Pytorch 0.4.1+

```
pip install -r requirements.txt
```

## Usage

### Preprocess 
- download [Places2](http://places2.csail.mit.edu/) and place it somewhere. The dataset should contain `data_large`, `val_large`, and `test_large` as the subdirectories. Don't forget to specify the root of the dataset by `--root ROOT` when using `train.py` or `test.py`

- Generate masks by following [1] (saved under `./masks` by default). **Note that the way of the mask generation is different from the original work**
```
python generate_data.py
```

### Train
```
CUDA_VISIBLE_DEVICES=<gpu_id> python train.py
```

### Fine-tune
```
CUDA_VISIBLE_DEVICES=<gpu_id> python train.py --finetune --resume <checkpoint_name>
```
### Test
```
CUDA_VISIBLE_DEVICES=<gpu_id> python test.py --snapshot <snapshot_path>
```

## Results

Here are some results from the test set after the training of 500,000 iterations and fine-tuning (freezing BN in encoder) of 500,000 iterations. The model is available [here](https://drive.google.com/open?id=1SYjJ-Vlu2cpAlgBG5FiJueN9W4lf48w8), but I don't ensure the quality.
(Top to bottom: input, mask, image generated by the network, image which is combined with the original non-masked region of image, ground truth)
![Results](result_iter_1000000.jpg)

## References
- [1]: [Unofficial implementation in Chainer](https://github.com/SeitaroShinagawa/chainer-partial_convolution_image_inpainting)
